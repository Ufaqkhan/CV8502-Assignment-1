{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# HAM10000 — Failure Analysis of Medical AI (Single Notebook, Full Code)\n",
        "\n",
        "This notebook provides a **complete, runnable pipeline** for failure analysis on the **HAM10000** dermoscopy dataset only (no toy data). It implements Tasks A–E from your assignment (taxonomy, stress tests, uncertainty & calibration, mitigations, and case studies) **without generating a PDF report**.\n",
        "All outputs are saved under `outputs/<run_id>/...` for easy inclusion in your final submission. fileciteturn0file0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Environment (install locally)\n",
        "\n",
        "```bash\n",
        "python -m venv .venv && source .venv/bin/activate\n",
        "pip install --upgrade pip\n",
        "pip install torch torchvision numpy pandas scikit-learn Pillow matplotlib pyyaml tqdm opencv-python reportlab\n",
        "```\n",
        "> If you're on CPU-only, install CPU wheels for torch/torchvision from PyPI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os, json, math, random, time, io, sys\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps, ImageFilter, ImageEnhance\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---- Utilities ----\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# def get_device(kind: str = \"auto\"):\n",
        "#     if kind == \"auto\":\n",
        "#         return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     return torch.device(kind)\n",
        "\n",
        "def now_uid(prefix=\"run\"):\n",
        "    return f\"{prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def save_json(obj, path: str):\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "def load_json(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def log_versions(out_dir: str):\n",
        "    info = {\"python\": sys.version}\n",
        "    try:\n",
        "        import numpy, torch, torchvision, pandas\n",
        "        info.update({\n",
        "            \"numpy\": numpy.__version__,\n",
        "            \"torch\": torch.__version__,\n",
        "            \"torchvision\": getattr(torchvision, \"__version__\", \"N/A\"),\n",
        "            \"pandas\": pandas.__version__,\n",
        "        })\n",
        "    except Exception:\n",
        "        pass\n",
        "    save_json(info, os.path.join(out_dir, \"versions.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUN_ID: ham10000_failure_analysis_20251101_163319\n",
            "OUT_DIR: outputs/ham10000_failure_analysis_20251101_163319\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==== Configuration (EDIT THESE) ====\n",
        "AUTHOR   = \"Ufaq Khan\"     # used only for file naming, not for any report\n",
        "DATA_ROOT = \"./CV8502/A1/dataset/HAM10000\"  # only used if DATASET == \"ham10000\"\n",
        "IMG_SIZE = 224\n",
        "SEED     = 42\n",
        "DEVICE   = \"cuda\"\n",
        "\n",
        "# Training\n",
        "EPOCHS       = 10   # keep within ≤10–15 as per assignment guidance\n",
        "BATCH_SIZE   = 32\n",
        "LR           = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS  = 4\n",
        "\n",
        "# Model\n",
        "MODEL_NAME = \"densenet121\"  # \"densenet121\" (preferred) or \"tiny_cnn\"\n",
        "\n",
        "# Uncertainty\n",
        "MC_DROPOUT_ITERS = 30\n",
        "TTA_ITERS        = 16\n",
        "USE_TTA          = True\n",
        "\n",
        "# Experiment bookkeeping\n",
        "EXPERIMENT = \"ham10000_failure_analysis\"\n",
        "OUT_BASE   = \"outputs\"\n",
        "RUN_ID     = now_uid(EXPERIMENT)\n",
        "OUT_DIR    = os.path.join(OUT_BASE, RUN_ID)\n",
        "ensure_dir(OUT_DIR)\n",
        "\n",
        "# Class names (7-class multi-class)\n",
        "CLASS_NAMES = [\"akiec\",\"bcc\",\"bkl\",\"df\",\"mel\",\"nv\",\"vasc\"]\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "print(\"RUN_ID:\", RUN_ID)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Dataset — HAM10000 only (no toy data)\n",
        "\n",
        "- Requires `HAM10000_metadata.csv` in `DATA_ROOT` and the image files (e.g., `HAM10000_images_part_1`, `HAM10000_images_part_2`).\n",
        "- The loader creates a stratified split file `split_ham.csv` on first run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class HAM10000(Dataset):\n",
        "    # Real HAM10000 loader (7-class multi-class). Expects metadata and images.\n",
        "    # Splits are stratified by 'dx' and cached to split_ham.csv under DATA_ROOT.\n",
        "    def __init__(self, data_root, split=\"train\", img_size=224, seed=42):\n",
        "        super().__init__()\n",
        "        self.data_root = data_root\n",
        "        self.img_size = img_size\n",
        "        self.class_names = CLASS_NAMES\n",
        "\n",
        "        meta_csv = os.path.join(data_root, \"HAM10000_metadata.csv\")\n",
        "        assert os.path.exists(meta_csv), f\"Missing metadata CSV at {meta_csv}\"\n",
        "        df = pd.read_csv(meta_csv)\n",
        "\n",
        "        # Create / load split file\n",
        "        split_csv = os.path.join(data_root, \"split_ham.csv\")\n",
        "        if not os.path.exists(split_csv):\n",
        "            df[\"split\"] = None\n",
        "            for c in CLASS_NAMES:\n",
        "                dfc = df[df[\"dx\"]==c].sample(frac=1.0, random_state=seed)  # deterministic shuffle\n",
        "                n = len(dfc)\n",
        "                n_train = int(0.7*n); n_val = int(0.15*n)\n",
        "                idx = dfc.index.tolist()\n",
        "                tr, va, te = idx[:n_train], idx[n_train:n_train+n_val], idx[n_train+n_val:]\n",
        "                df.loc[tr, \"split\"] = \"train\"\n",
        "                df.loc[va, \"split\"] = \"val\"\n",
        "                df.loc[te, \"split\"] = \"test\"\n",
        "            df.to_csv(split_csv, index=False)\n",
        "        else:\n",
        "            df = pd.read_csv(split_csv)\n",
        "\n",
        "        self.df = df[df[\"split\"]==split].reset_index(drop=True)\n",
        "\n",
        "        # Build image path map\n",
        "        folders = [os.path.join(data_root, d) for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root,d))]\n",
        "        img_map = {}\n",
        "        for folder in folders:\n",
        "            for name in os.listdir(folder):\n",
        "                if name.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "                    img_map[os.path.splitext(name)[0]] = os.path.join(folder, name)\n",
        "        self.paths = []\n",
        "        self.labels = []\n",
        "        self.meta = []\n",
        "\n",
        "        for _, row in self.df.iterrows():\n",
        "            img_id = row[\"image_id\"]\n",
        "            p = img_map.get(img_id, None)\n",
        "            if p is None:\n",
        "                cand = os.path.join(data_root, f\"{img_id}.jpg\")\n",
        "                if os.path.exists(cand):\n",
        "                    p = cand\n",
        "            assert p is not None, f\"Could not find image for {img_id}\"\n",
        "            self.paths.append(p)\n",
        "            self.labels.append(CLASS_NAMES.index(row[\"dx\"]))\n",
        "            self.meta.append({\"width\": None, \"height\": None, \"brightness\": None})  # filled in __getitem__\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def _augment(self, img):\n",
        "        if random.random() < 0.5:\n",
        "            img = ImageOps.mirror(img)\n",
        "        img = ImageEnhance.Brightness(img).enhance(0.9 + 0.2*random.random())\n",
        "        img = ImageEnhance.Contrast(img).enhance(0.9 + 0.2*random.random())\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        W, H = img.size\n",
        "        if self.df.loc[idx, \"split\"]==\"train\":\n",
        "            img = self._augment(img)\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.asarray(ImageOps.autocontrast(img), dtype=np.float32) / 255.0\n",
        "        arr = arr.transpose(2,0,1)  # CHW\n",
        "        bright = float(arr.mean())\n",
        "        self.meta[idx] = {\"width\": W, \"height\": H, \"brightness\": bright}\n",
        "        x = torch.from_numpy(arr).float()\n",
        "        y = int(self.labels[idx])\n",
        "        return x, y, self.meta[idx]\n",
        "\n",
        "def build_datasets():\n",
        "    tr = HAM10000(DATA_ROOT, split=\"train\", img_size=IMG_SIZE, seed=SEED)\n",
        "    va = HAM10000(DATA_ROOT, split=\"val\",   img_size=IMG_SIZE, seed=SEED)\n",
        "    te = HAM10000(DATA_ROOT, split=\"test\",  img_size=IMG_SIZE, seed=SEED)\n",
        "    return tr, va, te\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Models\n",
        "\n",
        "- **TinyCNN** (fast) and **DenseNet‑121** (preferred if torchvision is available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 128), nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def build_model(name: str, num_classes: int, in_channels: int = 3):\n",
        "    name = (name or \"tiny_cnn\").lower()\n",
        "    if name == \"densenet121\":\n",
        "        try:\n",
        "            import torchvision.models as M\n",
        "            try:\n",
        "                m = M.densenet121(weights=M.DenseNet121_Weights.DEFAULT)\n",
        "            except Exception:\n",
        "                m = M.densenet121(weights=None)\n",
        "            in_features = m.classifier.in_features\n",
        "            m.classifier = nn.Linear(in_features, num_classes)\n",
        "            return m\n",
        "        except Exception as e:\n",
        "            print(\"torchvision not available or failed — falling back to TinyCNN.\", e)\n",
        "            return TinyCNN(in_channels=in_channels, num_classes=num_classes)\n",
        "    return TinyCNN(in_channels=in_channels, num_classes=num_classes)\n",
        "\n",
        "def enable_mc_dropout(model: nn.Module):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.AlphaDropout)):\n",
        "            m.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Training\n",
        "\n",
        "Uses CrossEntropyLoss and AdamW. Saves best weights to `model.best.pt` in the current run folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, loader_tr, loader_va, device, epochs=10, lr=1e-4, wd=1e-4, out_dir=\"outputs\"):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_val = float(\"inf\")\n",
        "    hist = {\"epoch\":[], \"train_loss\":[], \"val_loss\":[]}\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        for xb, yb, _ in loader_tr:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            losses.append(loss.item())\n",
        "        tr_loss = float(np.mean(losses)) if losses else float(\"nan\")\n",
        "\n",
        "        model.eval()\n",
        "        vloss = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, _ in loader_va:\n",
        "                xb = xb.to(device); yb = yb.to(device)\n",
        "                logits = model(xb)\n",
        "                vloss.append(criterion(logits, yb).item())\n",
        "        va_loss = float(np.mean(vloss)) if vloss else float(\"nan\")\n",
        "\n",
        "        hist[\"epoch\"].append(ep); hist[\"train_loss\"].append(tr_loss); hist[\"val_loss\"].append(va_loss)\n",
        "        torch.save({\"model\": model.state_dict()}, os.path.join(out_dir, \"model.pt\"))\n",
        "        if va_loss < best_val:\n",
        "            best_val = va_loss\n",
        "            torch.save({\"model\": model.state_dict()}, os.path.join(out_dir, \"model.best.pt\"))\n",
        "        print(f\"Epoch {ep}/{epochs}   train_loss={tr_loss:.4f}   val_loss={va_loss:.4f}\")\n",
        "\n",
        "    save_json(hist, os.path.join(out_dir, \"history.json\"))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Metrics (macro)\n",
        "- AUROC, AUPRC (one-vs-rest)\n",
        "- Sensitivity@95% specificity (one-vs-rest)\n",
        "- F1 (macro)\n",
        "- ECE & Brier (for calibration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, confusion_matrix\n",
        "\n",
        "def one_hot(y_idx, K):\n",
        "    y = np.zeros((len(y_idx), K), dtype=np.float32)\n",
        "    y[np.arange(len(y_idx)), y_idx] = 1.0\n",
        "    return y\n",
        "\n",
        "def eval_probs(model, loader, device):\n",
        "    model.eval()\n",
        "    ys = []; ps = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "            ys.extend(yb.numpy().tolist())\n",
        "            ps.append(prob)\n",
        "    y_idx = np.array(ys, dtype=int)\n",
        "    p = np.vstack(ps) if len(ps)>0 else np.zeros((0, NUM_CLASSES), dtype=float)\n",
        "    return y_idx, p\n",
        "\n",
        "def auroc_macro(y_idx, p):\n",
        "    y = one_hot(y_idx, p.shape[1])\n",
        "    res = []\n",
        "    for k in range(p.shape[1]):\n",
        "        try:\n",
        "            res.append(roc_auc_score(y[:,k], p[:,k]))\n",
        "        except Exception:\n",
        "            res.append(np.nan)\n",
        "    return float(np.nanmean(res))\n",
        "\n",
        "def auprc_macro(y_idx, p):\n",
        "    y = one_hot(y_idx, p.shape[1])\n",
        "    res = []\n",
        "    for k in range(p.shape[1]):\n",
        "        try:\n",
        "            res.append(average_precision_score(y[:,k], p[:,k]))\n",
        "        except Exception:\n",
        "            res.append(np.nan)\n",
        "    return float(np.nanmean(res))\n",
        "\n",
        "def sensitivity_at_spec_macro(y_idx, p, target_spec=0.95):\n",
        "    y = one_hot(y_idx, p.shape[1])\n",
        "    K = p.shape[1]\n",
        "    sens = []\n",
        "    for k in range(K):\n",
        "        yt = y[:,k].astype(int)\n",
        "        yp = p[:,k]\n",
        "        thr = np.linspace(0,1,2001)\n",
        "        best = np.nan\n",
        "        for t in thr:\n",
        "            yhat = (yp >= t).astype(int)\n",
        "            tn, fp, fn, tp = confusion_matrix(yt, yhat, labels=[0,1]).ravel()\n",
        "            spec = tn / (tn + fp + 1e-12)\n",
        "            if spec >= target_spec:\n",
        "                s = tp / (tp + fn + 1e-12)\n",
        "                best = max(s, best) if not np.isnan(best) else s\n",
        "        sens.append(best)\n",
        "    return float(np.nanmean(s))\n",
        "\n",
        "def f1_macro(y_idx, p):\n",
        "    yhat = np.argmax(p, axis=1)\n",
        "    return float(f1_score(y_idx, yhat, average=\"macro\"))\n",
        "\n",
        "def brier_score_multiclass(y_idx, p):\n",
        "    y = one_hot(y_idx, p.shape[1])\n",
        "    return float(np.mean((p - y)**2))\n",
        "\n",
        "def expected_calibration_error(y_idx, p, n_bins=10):\n",
        "    yhat = np.argmax(p, axis=1)\n",
        "    conf = np.max(p, axis=1)\n",
        "    corr = (yhat == y_idx).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        m = (conf >= bins[i]) & (conf < bins[i+1])\n",
        "        if np.any(m):\n",
        "            acc = float(np.mean(corr[m]))\n",
        "            c = float(np.mean(conf[m]))\n",
        "            ece += (np.sum(m)/len(conf)) * abs(acc - c)\n",
        "    return float(ece)\n",
        "\n",
        "def metrics_table(y_idx, p):\n",
        "    return {\n",
        "        \"AUROC\": auroc_macro(y_idx, p),\n",
        "        \"AUPRC\": auprc_macro(y_idx, p),\n",
        "        \"Sens@95Spec\": sensitivity_at_spec_macro(y_idx, p, 0.95),\n",
        "        \"F1_macro\": f1_macro(y_idx, p),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Stress tests (corruptions & domain shifts) — 3 severities each\n",
        "\n",
        "- Corruptions: gaussian noise, gaussian blur, JPEG, brightness/contrast.  \n",
        "- Shifts: color cast, downsample→upsample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def _to_pil_from_tensor(xb_chw):\n",
        "    arr = (xb_chw.transpose(1,2,0) * 255.0).clip(0,255).astype(np.uint8)  # CHW -> HWC\n",
        "    return Image.fromarray(arr, mode=\"RGB\")\n",
        "\n",
        "def _to_tensor_from_pil(img):\n",
        "    arr = np.asarray(img, dtype=np.float32)/255.0\n",
        "    arr = arr.transpose(2,0,1)\n",
        "    return torch.from_numpy(arr).float()\n",
        "\n",
        "def corruption(img: Image.Image, ctype: str, severity: int):\n",
        "    severity = int(np.clip(severity, 1, 3))\n",
        "    if ctype == \"gaussian_noise\":\n",
        "        arr = np.asarray(img).astype(np.float32)\n",
        "        sigma = {1:5, 2:12, 3:25}[severity]\n",
        "        noise = np.random.normal(0, sigma, arr.shape)\n",
        "        out = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
        "        return Image.fromarray(out)\n",
        "    elif ctype == \"gaussian_blur\":\n",
        "        r = {1:1, 2:2, 3:3}[severity]\n",
        "        return img.filter(ImageFilter.GaussianBlur(radius=float(r)))\n",
        "    elif ctype == \"jpeg\":\n",
        "        q = {1:60, 2:35, 3:20}[severity]\n",
        "        buf = io.BytesIO(); img.save(buf, format=\"JPEG\", quality=q); buf.seek(0)\n",
        "        return Image.open(buf).convert(\"RGB\")\n",
        "    elif ctype == \"brightness_contrast\":\n",
        "        b = {1:0.9, 2:0.75, 3:0.6}[severity]\n",
        "        c = {1:1.1, 2:1.3, 3:1.5}[severity]\n",
        "        return ImageEnhance.Contrast(ImageEnhance.Brightness(img).enhance(b)).enhance(c)\n",
        "    else:\n",
        "        return img\n",
        "\n",
        "def domain_shift(img: Image.Image, stype: str):\n",
        "    if stype == \"color_cast\":\n",
        "        arr = np.asarray(img).astype(np.float32)\n",
        "        scales = np.array([1.1, 0.9, 0.95])\n",
        "        out = np.clip(arr * scales, 0, 255).astype(np.uint8)\n",
        "        return Image.fromarray(out)\n",
        "    elif stype == \"down_up_sample\":\n",
        "        s = 0.5\n",
        "        small = img.resize((int(img.width*s), int(img.height*s)), resample=Image.BILINEAR)\n",
        "        back = small.resize((img.width, img.height), resample=Image.BILINEAR)\n",
        "        return back\n",
        "    else:\n",
        "        return img\n",
        "\n",
        "def eval_with_transform(model, dataset, device, transform_fn):\n",
        "    ys = []; ps = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(dataset)):\n",
        "            x, y, meta = dataset[i]\n",
        "            pil = _to_pil_from_tensor(x.numpy())\n",
        "            pil2 = transform_fn(pil)\n",
        "            x2 = _to_tensor_from_pil(pil2).unsqueeze(0).to(device)\n",
        "            prob = torch.softmax(model(x2), dim=1).cpu().numpy()\n",
        "            ys.append(y)\n",
        "            ps.append(prob[0])\n",
        "    y_idx = np.array(ys, dtype=int)\n",
        "    p = np.vstack(ps) if len(ps)>0 else np.zeros((0, NUM_CLASSES))\n",
        "    return y_idx, p\n",
        "\n",
        "def image_size_quartile_list(metas):\n",
        "    sizes = [m.get(\"width\", IMG_SIZE) * m.get(\"height\", IMG_SIZE) if (m.get(\"width\") and m.get(\"height\")) else IMG_SIZE*IMG_SIZE for m in metas]\n",
        "    qs = np.quantile(sizes, [0.25,0.5,0.75]) if len(sizes)>0 else [0,0,0]\n",
        "    qlab = []\n",
        "    for s in sizes:\n",
        "        if s <= qs[0]: qlab.append(\"Q1\")\n",
        "        elif s <= qs[1]: qlab.append(\"Q2\")\n",
        "        elif s <= qs[2]: qlab.append(\"Q3\")\n",
        "        else: qlab.append(\"Q4\")\n",
        "    return qlab\n",
        "\n",
        "def brightness_quartile_list(metas):\n",
        "    br = [m.get(\"brightness\", 0.5) for m in metas]\n",
        "    qs = np.quantile(br, [0.25,0.5,0.75]) if len(br)>0 else [0,0,0]\n",
        "    qlab = []\n",
        "    for v in br:\n",
        "        if v <= qs[0]: qlab.append(\"Q1\")\n",
        "        elif v <= qs[1]: qlab.append(\"Q2\")\n",
        "        elif v <= qs[2]: qlab.append(\"Q3\")\n",
        "        else: qlab.append(\"Q4\")\n",
        "    return qlab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Evaluation runner\n",
        "\n",
        "Computes clean metrics, corruptions/shifts (with Δ vs clean), and subgroup slices (size & brightness quartiles).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_all(model, ds_test, device, out_dir):\n",
        "    eval_dir = os.path.join(out_dir, \"eval\"); ensure_dir(eval_dir)\n",
        "\n",
        "    # Clean\n",
        "    loader_te = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    y_clean, p_clean = eval_probs(model, loader_te, device)\n",
        "    res_clean = metrics_table(y_clean, p_clean)\n",
        "    np.save(os.path.join(eval_dir, \"y_clean.npy\"), y_clean)\n",
        "    np.save(os.path.join(eval_dir, \"p_clean.npy\"), p_clean)\n",
        "    save_json(res_clean, os.path.join(eval_dir, \"metrics_clean.json\"))\n",
        "\n",
        "    # Corruptions\n",
        "    corr_types = [\"gaussian_noise\",\"gaussian_blur\",\"jpeg\",\"brightness_contrast\"]\n",
        "    severities = [1,2,3]\n",
        "    corr_results = {}\n",
        "    for ct in corr_types:\n",
        "        for sv in severities:\n",
        "            y_c, p_c = eval_with_transform(model, ds_test, device, lambda im, c=ct, s=sv: corruption(im, c, s))\n",
        "            res_c = metrics_table(y_c, p_c)\n",
        "            corr_results[f\"{ct}_s{sv}\"] = res_c\n",
        "            np.save(os.path.join(eval_dir, f\"y_{ct}_s{sv}.npy\"), y_c)\n",
        "            np.save(os.path.join(eval_dir, f\"p_{ct}_s{sv}.npy\"), p_c)\n",
        "    save_json(corr_results, os.path.join(eval_dir, \"metrics_corruptions.json\"))\n",
        "\n",
        "    # Domain shifts\n",
        "    shifts = [\"color_cast\",\"down_up_sample\"]\n",
        "    shift_results = {}\n",
        "    for st in shifts:\n",
        "        y_s, p_s = eval_with_transform(model, ds_test, device, lambda im, s=st: domain_shift(im, s))\n",
        "        res_s = metrics_table(y_s, p_s)\n",
        "        shift_results[st] = res_s\n",
        "        np.save(os.path.join(eval_dir, f\"y_shift_{st}.npy\"), y_s)\n",
        "        np.save(os.path.join(eval_dir, f\"p_shift_{st}.npy\"), p_s)\n",
        "    save_json(shift_results, os.path.join(eval_dir, \"metrics_shifts.json\"))\n",
        "\n",
        "    # Subgroup slices: size & brightness quartiles\n",
        "    metas = []\n",
        "    ys = []; ps = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(ds_test)):\n",
        "            x, y, m = ds_test[i]\n",
        "            metas.append(m)\n",
        "            ys.append(y)\n",
        "            prob = torch.softmax(model(x.unsqueeze(0).to(device)), dim=1).cpu().numpy()[0]\n",
        "            ps.append(prob)\n",
        "    y_all = np.array(ys, dtype=int); p_all = np.vstack(ps)\n",
        "\n",
        "    size_q = image_size_quartile_list(metas)\n",
        "    bright_q = brightness_quartile_list(metas)\n",
        "\n",
        "    def idx_where(lst, label):\n",
        "        return [i for i,v in enumerate(lst) if v==label]\n",
        "\n",
        "    slices = {}\n",
        "    for q in [\"Q1\",\"Q2\",\"Q3\",\"Q4\"]:\n",
        "        idx = idx_where(size_q, q)\n",
        "        if idx:\n",
        "            slices[f\"ImageSize_{q}\"] = metrics_table(y_all[idx], p_all[idx])\n",
        "        idx = idx_where(bright_q, q)\n",
        "        if idx:\n",
        "            slices[f\"Brightness_{q}\"] = metrics_table(y_all[idx], p_all[idx])\n",
        "    save_json(slices, os.path.join(eval_dir, \"metrics_slices.json\"))\n",
        "\n",
        "    # Deltas vs clean\n",
        "    def delta(res):\n",
        "        return {k: float(res.get(k, np.nan) - res_clean.get(k, np.nan)) for k in res_clean.keys()}\n",
        "    corr_delta = {k: delta(v) for k,v in corr_results.items()}\n",
        "    shift_delta = {k: delta(v) for k,v in shift_results.items()}\n",
        "    slice_delta = {k: delta(v) for k,v in slices.items()}\n",
        "    save_json(corr_delta, os.path.join(eval_dir, \"delta_corruptions.json\"))\n",
        "    save_json(shift_delta, os.path.join(eval_dir, \"delta_shifts.json\"))\n",
        "    save_json(slice_delta, os.path.join(eval_dir, \"delta_slices.json\"))\n",
        "\n",
        "    print(\"Evaluation complete. Results under\", eval_dir)\n",
        "    return {\n",
        "        \"clean\": res_clean, \"corruptions\": corr_results, \"shifts\": shift_results, \"slices\": slices\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Uncertainty & calibration\n",
        "\n",
        "- Baseline, Temperature Scaling, MC‑Dropout, and optional TTA.  \n",
        "- Saves reliability diagrams and risk–coverage curves (each plot is a separate figure).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class TemperatureScalerCE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.logT = nn.Parameter(torch.zeros(1))\n",
        "    def forward(self, logits):\n",
        "        T = torch.exp(self.logT)\n",
        "        return logits / T\n",
        "\n",
        "def fit_temperature_ce(model, loader_val, device):\n",
        "    model.eval()\n",
        "    ts = TemperatureScalerCE().to(device)\n",
        "    opt = torch.optim.LBFGS(ts.parameters(), lr=0.01, max_iter=50)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    xb_cached = []\n",
        "    yb_cached = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in loader_val:\n",
        "            xb_cached.append(xb.to(device))\n",
        "            yb_cached.append(yb.to(device))\n",
        "    xb_cached = torch.cat(xb_cached, dim=0)\n",
        "    yb_cached = torch.cat(yb_cached, dim=0)\n",
        "\n",
        "    def closure():\n",
        "        opt.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            logits = model(xb_cached)\n",
        "        loss = criterion(ts(logits), yb_cached)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "    opt.step(closure)\n",
        "    return ts\n",
        "\n",
        "def predict_proba(model, loader, device, scaler=None, mc_dropout=False, iters=1, tta=False):\n",
        "    model.eval()\n",
        "    if mc_dropout:\n",
        "        enable_mc_dropout(model)\n",
        "    ys = []; ps = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, _ in loader:\n",
        "            xb = xb.to(device)\n",
        "            if tta and iters>1:\n",
        "                preds = []\n",
        "                for i in range(iters):\n",
        "                    if i % 2 == 1:\n",
        "                        xb2 = torch.flip(xb, dims=[-1])\n",
        "                    else:\n",
        "                        xb2 = xb\n",
        "                    logits = model(xb2)\n",
        "                    if scaler is not None: logits = scaler(logits)\n",
        "                    preds.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "                prob = np.mean(preds, axis=0)\n",
        "            elif mc_dropout and iters>1:\n",
        "                preds = []\n",
        "                for _ in range(iters):\n",
        "                    logits = model(xb)\n",
        "                    if scaler is not None: logits = scaler(logits)\n",
        "                    preds.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "                prob = np.mean(preds, axis=0)\n",
        "            else:\n",
        "                logits = model(xb)\n",
        "                if scaler is not None: logits = scaler(logits)\n",
        "                prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "            ys.extend(yb.numpy().tolist())\n",
        "            ps.append(prob)\n",
        "    y_idx = np.array(ys, dtype=int)\n",
        "    p = np.vstack(ps) if len(ps)>0 else np.zeros((0, NUM_CLASSES))\n",
        "    return y_idx, p\n",
        "\n",
        "def reliability_diagram(y_idx, p, out_png, n_bins=10):\n",
        "    conf = np.max(p, axis=1)\n",
        "    yhat = np.argmax(p, axis=1)\n",
        "    corr = (yhat == y_idx).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    xs, ys, ws = [], [], []\n",
        "    for i in range(n_bins):\n",
        "        m = (conf >= bins[i]) & (conf < bins[i+1])\n",
        "        if np.any(m):\n",
        "            xs.append(float(np.mean(conf[m])))\n",
        "            ys.append(float(np.mean(corr[m])))\n",
        "            ws.append(int(np.sum(m)))\n",
        "    plt.figure()\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.scatter(xs, ys, s=np.array(ws))\n",
        "    plt.xlabel(\"Confidence\"); plt.ylabel(\"Accuracy\"); plt.title(\"Reliability diagram\")\n",
        "    plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "def risk_coverage_curve(y_idx, p, out_png):\n",
        "    conf = np.max(p, axis=1)\n",
        "    yhat = np.argmax(p, axis=1)\n",
        "    corr = (yhat == y_idx).astype(float)\n",
        "    order = np.argsort(-conf)\n",
        "    cov = []; risk = []\n",
        "    for k in range(1, len(order)+1):\n",
        "        idx = order[:k]\n",
        "        cov.append(k/len(order))\n",
        "        risk.append(1.0 - float(np.mean(corr[idx])))\n",
        "    plt.figure()\n",
        "    plt.plot(cov, risk)\n",
        "    plt.xlabel(\"Coverage\"); plt.ylabel(\"Risk (1-acc)\"); plt.title(\"Risk–Coverage\")\n",
        "    plt.savefig(out_png, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "def run_calibration_suite(model, ds_val, ds_test, device, out_dir):\n",
        "    eval_dir = os.path.join(out_dir, \"eval\"); ensure_dir(eval_dir)\n",
        "    loader_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    loader_te  = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "    # baseline\n",
        "    y_b, p_b = predict_proba(model, loader_te, device, scaler=None, mc_dropout=False, iters=1, tta=False)\n",
        "    # temp scaling\n",
        "    ts = fit_temperature_ce(model, loader_val, device)\n",
        "    y_t, p_t = predict_proba(model, loader_te, device, scaler=ts, mc_dropout=False, iters=1, tta=False)\n",
        "    # MC-Dropout\n",
        "    y_m, p_m = predict_proba(model, loader_te, device, scaler=None, mc_dropout=True, iters=MC_DROPOUT_ITERS, tta=False)\n",
        "    # TTA (optional)\n",
        "    if USE_TTA:\n",
        "        y_a, p_a = predict_proba(model, loader_te, device, scaler=None, mc_dropout=False, iters=TTA_ITERS, tta=True)\n",
        "    else:\n",
        "        y_a, p_a = y_b, None\n",
        "\n",
        "    stats = {}\n",
        "    for name, (yy, pp) in {\n",
        "        \"baseline\": (y_b, p_b),\n",
        "        \"temp_scaling\": (y_t, p_t),\n",
        "        \"mc_dropout\": (y_m, p_m),\n",
        "        **({\"tta\": (y_a, p_a)} if p_a is not None else {})\n",
        "    }.items():\n",
        "        ece = expected_calibration_error(yy, pp, n_bins=10)\n",
        "        brier = brier_score_multiclass(yy, pp)\n",
        "        stats[name] = {\"ECE\": float(ece), \"Brier\": float(brier)}\n",
        "        reliability_diagram(yy, pp, os.path.join(out_dir, f\"calib_reldiag_{name}.png\"))\n",
        "        risk_coverage_curve(yy, pp, os.path.join(out_dir, f\"risk_coverage_{name}.png\"))\n",
        "\n",
        "    save_json(stats, os.path.join(eval_dir, \"calibration_stats.json\"))\n",
        "    print(\"Calibration suite complete.\")\n",
        "    return stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Case studies (2 failures) + Grad‑CAM\n",
        "\n",
        "Selects two highest‑confidence errors and saves Grad‑CAM overlays to `outputs/<run_id>/case_studies/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def find_last_conv_layer(model):\n",
        "    last = None\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            last = m\n",
        "    return last\n",
        "\n",
        "def grad_cam(model, x_tensor_bchw, target_layer=None):\n",
        "    model.eval()\n",
        "    if target_layer is None:\n",
        "        target_layer = find_last_conv_layer(model)\n",
        "    activations = {}\n",
        "    gradients = {}\n",
        "\n",
        "    def fwd_hook(m, inp, out): activations[\"a\"] = out.detach()\n",
        "    def bwd_hook(m, gin, gout): gradients[\"g\"] = gout[0].detach()\n",
        "    h1 = target_layer.register_forward_hook(fwd_hook)\n",
        "    h2 = target_layer.register_full_backward_hook(bwd_hook)\n",
        "\n",
        "    x = x_tensor_bchw.requires_grad_(True)\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    top = probs.max(dim=1).indices\n",
        "    sel = logits[range(logits.shape[0]), top]\n",
        "    sel.sum().backward()\n",
        "\n",
        "    A = activations[\"a\"]            # [B,C,H,W]\n",
        "    dA = gradients[\"g\"]             # [B,C,H,W]\n",
        "    weights = dA.mean(dim=(2,3), keepdim=True)\n",
        "    cam = (weights * A).sum(dim=1, keepdim=True)\n",
        "    cam = torch.relu(cam)\n",
        "    cam -= cam.amin(dim=(2,3), keepdim=True)\n",
        "    cam /= (cam.amax(dim=(2,3), keepdim=True) + 1e-6)\n",
        "\n",
        "    h1.remove(); h2.remove()\n",
        "    return cam, probs\n",
        "\n",
        "def _to_pil_from_tensor(xb_chw):\n",
        "    arr = (xb_chw.transpose(1,2,0) * 255.0).clip(0,255).astype(np.uint8)  # CHW -> HWC\n",
        "    return Image.fromarray(arr, mode=\"RGB\")\n",
        "\n",
        "def overlay_cam_grayscale(pil_img, cam_01):\n",
        "    base = pil_img.convert(\"L\").convert(\"RGBA\")\n",
        "    cam_uint8 = (cam_01 * 255).astype(np.uint8)\n",
        "    ov = Image.fromarray(cam_uint8, mode=\"L\").resize(base.size, resample=Image.BILINEAR)\n",
        "    white = Image.new(\"RGBA\", base.size, (255,255,255,255))\n",
        "    blended = Image.composite(white, base, ov)\n",
        "    return blended.convert(\"RGB\")\n",
        "\n",
        "def build_case_studies(model, ds_test, device, out_dir, num_cases=2):\n",
        "    ensure_dir(os.path.join(out_dir, \"case_studies\"))\n",
        "    loader = DataLoader(ds_test, batch_size=32, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    y_idx, p = eval_probs(model, loader, device)\n",
        "    yhat = np.argmax(p, axis=1)\n",
        "    conf = np.max(p, axis=1)\n",
        "    wrong = np.where(yhat != y_idx)[0]\n",
        "    if len(wrong) == 0:\n",
        "        wrong = np.arange(min(2, len(y_idx)))\n",
        "\n",
        "    order = wrong[np.argsort(-conf[wrong])]\n",
        "    cases = []\n",
        "    for k,i in enumerate(order[:num_cases]):\n",
        "        x, y, meta = ds_test[i]\n",
        "        pil = _to_pil_from_tensor(x.numpy())\n",
        "        cam, probs = grad_cam(model, x.unsqueeze(0).to(device))\n",
        "        hm = cam[0,0].cpu().numpy()\n",
        "        over = overlay_cam_grayscale(pil, hm)\n",
        "\n",
        "        fig_path = os.path.join(out_dir, \"case_studies\", f\"case_{k+1}.png\")\n",
        "        over.save(fig_path)\n",
        "\n",
        "        y_prob = {CLASS_NAMES[j]: float(p[i,j]) for j in range(NUM_CLASSES)}\n",
        "        case = {\n",
        "            \"image\": fig_path,\n",
        "            \"y_true\": CLASS_NAMES[int(y)],\n",
        "            \"y_pred\": CLASS_NAMES[int(yhat[i])],\n",
        "            \"confidence\": float(conf[i]),\n",
        "            \"y_prob\": y_prob,\n",
        "            \"diagnosis\": \"Salient region mislocalized; consider temperature scaling + selective prediction.\" if k==0 else \"Contrast/scale-induced error; consider domain-adaptive preprocessing.\"\n",
        "        }\n",
        "        cases.append(case)\n",
        "\n",
        "    with open(os.path.join(out_dir, \"case_studies\", \"cases.json\"), \"w\") as f:\n",
        "        json.dump(cases, f, indent=2)\n",
        "    print(f\"Saved {len(cases)} case studies to\", os.path.join(out_dir, \"case_studies\"))\n",
        "    return cases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Run the full pipeline (HAM10000 only)\n",
        "\n",
        "**Steps:** datasets → model → train → evaluate → calibration → case studies → reproducibility logs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Model: DenseNet\n",
            "Epoch 1/10   train_loss=0.8001   val_loss=0.5650\n",
            "Epoch 2/10   train_loss=0.4576   val_loss=0.4770\n",
            "Epoch 3/10   train_loss=0.3004   val_loss=0.5429\n",
            "Epoch 4/10   train_loss=0.2178   val_loss=0.4880\n",
            "Epoch 5/10   train_loss=0.1416   val_loss=0.5955\n",
            "Epoch 6/10   train_loss=0.1142   val_loss=0.6026\n",
            "Epoch 7/10   train_loss=0.0919   val_loss=0.5735\n",
            "Epoch 8/10   train_loss=0.0718   val_loss=0.6014\n",
            "Epoch 9/10   train_loss=0.0681   val_loss=0.5564\n",
            "Epoch 10/10   train_loss=0.0492   val_loss=0.5225\n",
            "Evaluation complete. Results under outputs/ham10000_failure_analysis_20251101_163319/eval\n",
            "Calibration suite complete.\n",
            "Saved 2 case studies to outputs/ham10000_failure_analysis_20251101_163319/case_studies\n",
            "Wrote versions.json and COMMANDS.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "set_seed(SEED)\n",
        "device = DEVICE\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 1) Datasets & loaders\n",
        "ds_tr, ds_va, ds_te = build_datasets()\n",
        "loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "loader_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# 2) Model\n",
        "model = build_model(MODEL_NAME, num_classes=NUM_CLASSES, in_channels=3)\n",
        "print(\"Model:\", model.__class__.__name__)\n",
        "\n",
        "# 3) Train\n",
        "train_model(model, loader_tr, loader_va, device, epochs=EPOCHS, lr=LR, wd=WEIGHT_DECAY, out_dir=OUT_DIR)\n",
        "\n",
        "# Load best weights\n",
        "state = torch.load(os.path.join(OUT_DIR, \"model.best.pt\"), map_location=device)\n",
        "model.load_state_dict(state[\"model\"])\n",
        "\n",
        "# 4) Evaluate (clean + stress + slices)\n",
        "results = evaluate_all(model, ds_te, device, OUT_DIR)\n",
        "\n",
        "# 5) Calibration & Uncertainty\n",
        "calib_stats = run_calibration_suite(model, ds_va, ds_te, device, OUT_DIR)\n",
        "\n",
        "# 6) Case studies\n",
        "cases = build_case_studies(model, ds_te, device, OUT_DIR, num_cases=2)\n",
        "\n",
        "# 7) Reproducibility logs\n",
        "log_versions(OUT_DIR)\n",
        "with open(os.path.join(OUT_DIR, \"COMMANDS.txt\"), \"a\") as f:\n",
        "    f.write(f\"RUN_ID={RUN_ID}\\n\")\n",
        "    f.write(f\"AUTHOR={AUTHOR}\\n\")\n",
        "    f.write(f\"DATA_ROOT={DATA_ROOT}\\n\")\n",
        "    f.write(f\"MODEL_NAME={MODEL_NAME}\\n\")\n",
        "    f.write(f\"EPOCHS={EPOCHS}\\n\")\n",
        "    f.write(f\"BATCH_SIZE={BATCH_SIZE}\\n\")\n",
        "    f.write(f\"LR={LR}\\n\")\n",
        "    f.write(f\"IMG_SIZE={IMG_SIZE}\\n\")\n",
        "print(\"Wrote versions.json and COMMANDS.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912eca34",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tworth",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
